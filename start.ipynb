{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchaudio\n",
    "from torchaudio import datasets, transforms\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#Processing the data:\n",
    "\n",
    "#transfer the nueral net onto a gpu\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device) #this shiuld print the device that is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to load Noisy Speech Data\n",
    "\n",
    "def load(file_path):\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    return waveform, sample_rate\n",
    "\n",
    "transform = transforms.MelSpectrogram(sample_rate=8000, n_mels=128)\n",
    "#sample rate of 8Hkz\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "class NosiySpeech(Dataset):\n",
    "    def __init__(self, path, transform=None, device=device):\n",
    "        self.List = []\n",
    "        for f in os.listdir(path):\n",
    "            if f.endswith('.wav'):\n",
    "                self.List.append(f)      \n",
    "        self.pathsList = self.List  \n",
    "        self.path = path\n",
    "        self.transform = transform \n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pathsList)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        waveform, sample_rate = load(self.pathsList[idx])\n",
    "        waveform = transform(waveform)\n",
    "\n",
    "        return waveform\n",
    "    \n",
    "\n",
    "\n",
    "noisy_train = \"\\\\Users\\\\Maisoon\\\\Documents\\\\Audio-Signal-Denoising-Project-\\\\noisy_trainset_28spk_wav\"\n",
    "noisy_test = \"\\\\Users\\\\Maisoon\\\\Documents\\\\Audio-Signal-Denoising-Project-\\\\noisy_testset_wav\"\n",
    "\n",
    "clean_train= \"\\\\Users\\\\Maisoon\\\\Documents\\\\Audio-Signal-Denoising-Project-\\\\clean_trainset_28spk_wav\"\n",
    "clean_test = \"\\\\Users\\\\Maisoon\\\\Documents\\\\Audio-Signal-Denoising-Project-\\\\clean_testset_wav\"\n",
    "\n",
    "#noisy training data\n",
    "nosiy_trainDataset = NosiySpeech(path=noisy_train, transform=transform)\n",
    "#print(nosiy_trainDataset.pathsList)\n",
    "noisy_trainDataloader = DataLoader(nosiy_trainDataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#noisy test data\n",
    "nosiy_testDataset = NosiySpeech(path=noisy_test, transform=transform)\n",
    "noisy_testDataloader = DataLoader(nosiy_trainDataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#clean training data\n",
    "clean_trainDataset = NosiySpeech(path=clean_train, transform=transform)\n",
    "clean_trainDataloader = DataLoader(nosiy_trainDataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#clean test data\n",
    "clean_testDataset = NosiySpeech(path=clean_test, transform=transform)\n",
    "clean_testDataloader = DataLoader(nosiy_trainDataset, batch_size=32, shuffle=True)\n",
    "\n",
    "filename = nosiy_trainDataset.pathsList[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclass DenoisingLinearModel(nn.Module):\\n    def __init__(self, input, output):\\n        super(DenoisingLinearModel, self).__init__()\\n        self.linear = nn.Linear(input, output) ##one layer to \\n\\n    def forward(self, x):\\n        x = self.linear(x)\\n        return x\\n    \\ninput_var = 150\\noutput_var = 150\\n\\nln_model = DenoisingLinearModel(input_var, output_var)\\n\\nloss_fn = nn.MSELoss()\\noptimizer=torch.optim.SGD(ln_model, lr = 0.01)\\n\\ncorrect = 0\\ntotal = 0\\n\\nnum_epochs = 10\\nfor epoch in range(num_epochs):\\n    for noisy, clean in clean_trainDataloader:\\n        #noisy, clean = data\\n        output = ln_model(noisy)\\n        _, predicted = torch.max(output.data, 1)\\n        loss = loss_fn(output, clean)\\n        total += clean.size(0)\\n        correct += (predicted == clean).sum().item()\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n\\nprint(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\\n\""
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class DenoisingLinearModel(nn.Module):\n",
    "    def __init__(self, input, output):\n",
    "        super(DenoisingLinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(input, output) ##one layer to \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "input_var = 150\n",
    "output_var = 150\n",
    "\n",
    "ln_model = DenoisingLinearModel(input_var, output_var)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer=torch.optim.SGD(ln_model, lr = 0.01)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for noisy, clean in clean_trainDataloader:\n",
    "        #noisy, clean = data\n",
    "        output = ln_model(noisy)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        loss = loss_fn(output, clean)\n",
    "        total += clean.size(0)\n",
    "        correct += (predicted == clean).sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Couldn't find appropriate backend to handle uri p250_155.wav and format None.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[305], line 98\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m     95\u001b[0m         one_epoch(model,dataloader,loss_fn\u001b[38;5;241m=\u001b[39mcriterion,optimizer\u001b[38;5;241m=\u001b[39moptimizer,device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m---> 98\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnoisy_trainDataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[305], line 95\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, loss_fn, optimizer, device, num_epochs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model,dataloader,loss_fn,optimizer,device,num_epochs):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 95\u001b[0m         \u001b[43mone_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[305], line 79\u001b[0m, in \u001b[0;36mone_epoch\u001b[1;34m(model, dataloader, loss_fn, optimizer, device)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_epoch\u001b[39m(model,dataloader,loss_fn,optimizer,device):\n\u001b[1;32m---> 79\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#forward pass \u001b[39;49;00m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Maisoon\\Documents\\Audio-Signal-Denoising-Project-\\.conda\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Maisoon\\Documents\\Audio-Signal-Denoising-Project-\\.conda\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Maisoon\\Documents\\Audio-Signal-Denoising-Project-\\.conda\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Maisoon\\Documents\\Audio-Signal-Denoising-Project-\\.conda\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[303], line 28\u001b[0m, in \u001b[0;36mNosiySpeech.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 28\u001b[0m     waveform, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpathsList\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     waveform \u001b[38;5;241m=\u001b[39m transform(waveform)\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m waveform\n",
      "Cell \u001b[1;32mIn[303], line 4\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(file_path):\n\u001b[1;32m----> 4\u001b[0m     waveform, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m waveform, sample_rate\n",
      "File \u001b[1;32mc:\\Users\\Maisoon\\Documents\\Audio-Signal-Denoising-Project-\\.conda\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:204\u001b[0m, in \u001b[0;36mget_load_func.<locals>.load\u001b[1;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m    119\u001b[0m     uri: Union[BinaryIO, \u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[0;32m    120\u001b[0m     frame_offset: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    126\u001b[0m     backend: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    127\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    By default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m            `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 204\u001b[0m     backend \u001b[38;5;241m=\u001b[39m \u001b[43mdispatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mload(uri, frame_offset, num_frames, normalize, channels_first, \u001b[38;5;28mformat\u001b[39m, buffer_size)\n",
      "File \u001b[1;32mc:\\Users\\Maisoon\\Documents\\Audio-Signal-Denoising-Project-\\.conda\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:116\u001b[0m, in \u001b[0;36mget_load_func.<locals>.dispatcher\u001b[1;34m(uri, format, backend_name)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mcan_decode(uri, \u001b[38;5;28mformat\u001b[39m):\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m backend\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find appropriate backend to handle uri \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and format \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mformat\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Couldn't find appropriate backend to handle uri p250_155.wav and format None."
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "#CNN\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "#CNN\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.maxPool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        #self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128*5*4, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #layer1\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        #layer 2\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        #layer 3 \n",
    "        x = self.conv3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        #flatten\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        #a fully conv layer with relu\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        #apply the dropout\n",
    "\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "net=Net().cuda()\n",
    "\n",
    "\n",
    "num_epoch = 2\n",
    "\n",
    "\n",
    "#instantiate the CNN model\n",
    "#cnn = Net()\n",
    "\n",
    "\n",
    "#Loss function and Optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "def one_epoch(model,dataloader,loss_fn,optimizer,device):\n",
    "    for input, output in dataloader:\n",
    "        #forward pass \n",
    "        input = input.to(device)\n",
    "        output = output.to(device)\n",
    "        outputs = model(input)\n",
    "        loss = loss_fn(outputs, output)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"loss:{loss.item()}\")\n",
    "    \n",
    "\n",
    "def train(model,dataloader,loss_fn,optimizer,device,num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        one_epoch(model,dataloader,loss_fn=criterion,optimizer=optimizer,device=device)\n",
    "\n",
    "\n",
    "train(net,noisy_trainDataloader,criterion,optimizer,device,num_epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
