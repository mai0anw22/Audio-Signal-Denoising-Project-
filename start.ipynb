{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchaudio\n",
    "from torchaudio import datasets, transforms\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing the data:\n",
    "\n",
    "#transfer the nueral net onto a gpu\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device) #this shiuld print the device that is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to load Noisy Speech Data\n",
    "\n",
    "def load(file_path):\n",
    "    waveform, sample_rate = torchaudio.load(uri=file_path)\n",
    "    return waveform, sample_rate\n",
    "\n",
    "transform = transforms.MelSpectrogram(sample_rate=8000, n_mels=128)\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "class NosiySpeech(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        self.transform = transform \n",
    "        self.pathsList = [os.path.join(p, f) for p, _, files in os.walk(path) for f in files if f.endswith('.wav')]\n",
    "        self.transforms_list = [transform(load(n)[0]) for n in self.pathsList]\n",
    "    def __len__(self):\n",
    "        return len(self.pathsList)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.transforms_list[idx], load(self.pathsList[idx])[1]\n",
    "    \n",
    "\n",
    "\n",
    "noisy_train = f\"\\\\Users\\\\Maisoon\\\\Documents\\\\Audio-Signal-Denoising-Project-\\\\noisy_trainset_28spk_wav\"\n",
    "noisy_test = f\"\\\\Users\\\\Maisoon\\\\Documents\\\\Audio-Signal-Denoising-Project-\\\\noisy_testset_wav\"\n",
    "\n",
    "clean_train= f\"\\\\Users\\\\Maisoon\\\\Documents\\\\Audio-Signal-Denoising-Project-\\\\clean_trainset_28spk_wav\"\n",
    "clean_test = f\"\\\\Users\\\\Maisoon\\\\Documents\\\\Audio-Signal-Denoising-Project-\\\\clean_testset_wav\"\n",
    "\n",
    "#noisy data\n",
    "nosiy_trainDataset = NosiySpeech(path=noisy_train, transform=transform)\n",
    "print(nosiy_trainDataset.pathsList)\n",
    "noisy_trainDataloader = DataLoader(nosiy_trainDataset, batch_size=32, shuffle=True)\n",
    "\n",
    "nosiy_testDataset = NosiySpeech(path=noisy_test, transform=transform)\n",
    "noisy_testDataloader = DataLoader(nosiy_trainDataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#clean data\n",
    "clean_trainDataset = NosiySpeech(path=clean_train, transform=transform)\n",
    "clean_trainDataloader = DataLoader(nosiy_trainDataset, batch_size=32, shuffle=True)\n",
    "\n",
    "clean_testDataset = NosiySpeech(path=clean_test, transform=transform)\n",
    "clean_testDataloader = DataLoader(nosiy_trainDataset, batch_size=32, shuffle=True)\n",
    "\n",
    "filename = nosiy_trainDataset.pathsList[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingLinearModel(nn.Module):\n",
    "    def __init__(self, input, output):\n",
    "        super(DenoisingLinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(input, output) ##one layer to \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "input_var = 150\n",
    "output_var = 150\n",
    "\n",
    "ln_model = DenoisingLinearModel(input_var, output_var)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer=torch.optim.SGD(ln_model, lr = 0.01)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for noisy, clean in clean_trainDataloader:\n",
    "        #noisy, clean = data\n",
    "        output = ln_model(noisy)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        loss = loss_fn(output, clean)\n",
    "        total += clean.size(0)\n",
    "        correct += (predicted == clean).sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.maxPool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        #self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128*5*4, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #layer1\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        #layer 2\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        #layer 3 \n",
    "        x = self.conv3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        #flatten\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        #a fully conv layer with relu\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        #apply the dropout\n",
    "\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "net=Net().cuda()\n",
    "\n",
    "\n",
    "num_epoch = 2\n",
    "\n",
    "\n",
    "#instantiate the CNN model\n",
    "#cnn = Net()\n",
    "\n",
    "\n",
    "#Loss function and Optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "def one_epoch(model,dataloader,loss_fn,optimizer,device):\n",
    "    for input, output in noisy_trainDataloader:\n",
    "        #forward pass \n",
    "        outputs = model(input)\n",
    "        loss = criterion(output, clean_trainDataloader)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"loss:{loss.item()}\")\n",
    "    \n",
    "\n",
    "def train(model,dataloader,loss_ln,optimizer,device,num_epochs):\n",
    "    for epoch in range(num_epoch):\n",
    "        one_epoch(model,dataloader,criterion,optimizer,device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function and Optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.01, momentum=0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
