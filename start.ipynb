{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchaudio\n",
    "from torchaudio import datasets, transforms\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#Processing the data:\n",
    "\n",
    "#transfer the nueral net onto a gpu\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device) #this shiuld print the device that is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to load Noisy Speech Data\n",
    "\n",
    "def load(file_path):\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    return waveform, sample_rate\n",
    "\n",
    "transform = transforms.MelSpectrogram(sample_rate=22050,n_fft=1024, hop_length=512, n_mels=64)\n",
    "#sample rate of 8Hkz\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "class NoisySpeech(Dataset):\n",
    "    def __init__(self, path, transform=None, device=device):\n",
    "        self.List = []\n",
    "        for f in os.listdir(path):\n",
    "            if f.endswith('.wav'):\n",
    "                self.List.append(f)      \n",
    "        self.pathsList = self.List  \n",
    "        self.path = path\n",
    "        self.transform = transform \n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pathsList)\n",
    "    \n",
    "\n",
    "\n",
    "transformed_data = []\n",
    "\n",
    "\n",
    "noisy_train = \"\\\\Users\\\\Maisoon\\\\Documents\\\\Audio-Signal-Denoising-Project-\\\\noisy_trainset_28spk_wav\"\n",
    "noisy_test = \"\\\\Users\\\\Maisoon\\\\Documents\\\\Audio-Signal-Denoising-Project-\\\\noisy_testset_wav\"\n",
    "\n",
    "clean_train= \"\\\\Users\\\\Maisoon\\\\Documents\\\\Audio-Signal-Denoising-Project-\\\\clean_trainset_28spk_wav\"\n",
    "clean_test = \"\\\\Users\\\\Maisoon\\\\Documents\\\\Audio-Signal-Denoising-Project-\\\\clean_testset_wav\"\n",
    "\n",
    "#noisy training data\n",
    "#nosiy_trainDataset = NoisySpeech(path=noisy_train, transform=transform)\n",
    "#print(nosiy_trainDataset.pathsList)\n",
    "#for i in nosiy_trainDataset.pathsList:\n",
    "#    p = torchaudio.load(i)\n",
    "#    t = transform(p)\n",
    "#    transformed_data.append(t)\n",
    "\n",
    "#noisy training data\n",
    "nosiy_trainDataset = NoisySpeech(path=noisy_train, transform=transform)\n",
    "#print(nosiy_trainDataset.pathsList)\n",
    "noisy_trainDataloader = DataLoader(nosiy_trainDataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#noisy test data\n",
    "nosiy_testDataset = NoisySpeech(path=noisy_test, transform=transform)\n",
    "noisy_testDataloader = DataLoader(nosiy_trainDataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#clean training data\n",
    "clean_trainDataset = NoisySpeech(path=clean_train, transform=transform)\n",
    "clean_trainDataloader = DataLoader(nosiy_trainDataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#clean test data\n",
    "clean_testDataset = NoisySpeech(path=clean_test, transform=transform)\n",
    "clean_testDataloader = DataLoader(nosiy_trainDataset, batch_size=32, shuffle=True)\n",
    "\n",
    "filename = nosiy_trainDataset.pathsList[0]\n",
    "\n",
    "filename = nosiy_trainDataset.pathsList[0]\n",
    "\n",
    "#CNN\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "#CNN\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "#CNN\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.maxPool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        #self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128*5*4, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #layer1\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        #layer 2\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        #layer 3 \n",
    "        x = self.conv3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        #flatten\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        #a fully conv layer with relu\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        #apply the dropout\n",
    "\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "net=Net().cuda()\n",
    "\n",
    "\n",
    "num_epoch = 2\n",
    "\n",
    "\n",
    "#instantiate the CNN model\n",
    "#cnn = Net()\n",
    "\n",
    "\n",
    "#Loss function and Optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "def one_epoch(model,dataloader,loss_fn,optimizer,device):\n",
    "    for input, output in dataloader:\n",
    "        #forward pass \n",
    "        input = input.to(device)\n",
    "        output = output.to(device)\n",
    "        outputs = model(input)\n",
    "        loss = loss_fn(outputs, output)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    #print(f\"loss:{loss.item()}\")\n",
    "    \n",
    "\n",
    "def train(model,dataloader,loss_fn,optimizer,device,num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        one_epoch(model,dataloader,loss_fn=criterion,optimizer=optimizer,device=device)\n",
    "\n",
    "\n",
    "train(net,transformed_data,criterion,optimizer,device,num_epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclass DenoisingLinearModel(nn.Module):\\n    def __init__(self, input, output):\\n        super(DenoisingLinearModel, self).__init__()\\n        self.linear = nn.Linear(input, output) ##one layer to \\n\\n    def forward(self, x):\\n        x = self.linear(x)\\n        return x\\n    \\ninput_var = 150\\noutput_var = 150\\n\\nln_model = DenoisingLinearModel(input_var, output_var)\\n\\nloss_fn = nn.MSELoss()\\noptimizer=torch.optim.SGD(ln_model, lr = 0.01)\\n\\ncorrect = 0\\ntotal = 0\\n\\nnum_epochs = 10\\nfor epoch in range(num_epochs):\\n    for noisy, clean in clean_trainDataloader:\\n        #noisy, clean = data\\n        output = ln_model(noisy)\\n        _, predicted = torch.max(output.data, 1)\\n        loss = loss_fn(output, clean)\\n        total += clean.size(0)\\n        correct += (predicted == clean).sum().item()\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n\\nprint(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class DenoisingLinearModel(nn.Module):\n",
    "    def __init__(self, input, output):\n",
    "        super(DenoisingLinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(input, output) ##one layer to \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "input_var = 150\n",
    "output_var = 150\n",
    "\n",
    "ln_model = DenoisingLinearModel(input_var, output_var)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer=torch.optim.SGD(ln_model, lr = 0.01)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for noisy, clean in clean_trainDataloader:\n",
    "        #noisy, clean = data\n",
    "        output = ln_model(noisy)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        loss = loss_fn(output, clean)\n",
    "        total += clean.size(0)\n",
    "        correct += (predicted == clean).sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport torch.nn as nn \\nimport torch.nn.functional as F\\n\\n#CNN\\nimport torch.nn as nn \\nimport torch.nn.functional as F\\n\\n#CNN\\n\\nimport torch.nn as nn \\nimport torch.nn.functional as F\\n\\nclass Net(nn.Module):\\n    def __init__(self):\\n        super().__init__()\\n        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\\n        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\\n        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\\n\\n        self.maxPool = nn.MaxPool2d(kernel_size=2)\\n\\n        #self.flatten = nn.Flatten()\\n        self.fc1 = nn.Linear(128*5*4, 128)\\n        self.fc2 = nn.Linear(128, 1)\\n\\n        self.dropout = nn.Dropout(0.5)\\n\\n        self.sigmoid = nn.Sigmoid()\\n\\n\\n    def forward(self, x):\\n        #layer1\\n        x = self.conv1(x)\\n        x = nn.functional.relu(x)\\n        x = self.pool(x)\\n\\n        #layer 2\\n        x = self.conv2(x)\\n        x = nn.functional.relu(x)\\n        x = self.pool(x)\\n\\n        #layer 3 \\n        x = self.conv3(x)\\n        x = nn.functional.relu(x)\\n        x = self.pool(x)\\n\\n        #flatten\\n        x = torch.flatten(x, 1)\\n\\n        #a fully conv layer with relu\\n        x = self.fc1(x)\\n        x = nn.functional.relu(x)\\n        x = self.dropout(x)\\n        #apply the dropout\\n\\n        x = self.sigmoid(x)\\n\\n        return x\\n    \\n\\nnet=Net().cuda()\\n\\n\\nnum_epoch = 2\\n\\n\\n#instantiate the CNN model\\n#cnn = Net()\\n\\n\\n#Loss function and Optimizer\\n\\ncriterion = nn.CrossEntropyLoss()\\noptimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\\n\\ndef one_epoch(model,dataloader,loss_fn,optimizer,device):\\n    for input, output in dataloader:\\n        #forward pass \\n        input = input.to(device)\\n        output = output.to(device)\\n        outputs = model(input)\\n        loss = loss_fn(outputs, output)\\n\\n        optimizer.zero_grad()\\n        loss.backward()\\n        optimizer.step()\\n\\n    print(f\"loss:{loss.item()}\")\\n    \\n\\ndef train(model,dataloader,loss_fn,optimizer,device,num_epochs):\\n    for epoch in range(num_epochs):\\n        one_epoch(model,dataloader,loss_fn=criterion,optimizer=optimizer,device=device)\\n\\n\\ntrain(net,noisy_trainDataloader,criterion,optimizer,device,num_epoch)\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CNN\n",
    "'''\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "#CNN\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "#CNN\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.maxPool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        #self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128*5*4, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #layer1\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        #layer 2\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        #layer 3 \n",
    "        x = self.conv3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        #flatten\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        #a fully conv layer with relu\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        #apply the dropout\n",
    "\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "net=Net().cuda()\n",
    "\n",
    "\n",
    "num_epoch = 2\n",
    "\n",
    "\n",
    "#instantiate the CNN model\n",
    "#cnn = Net()\n",
    "\n",
    "\n",
    "#Loss function and Optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "def one_epoch(model,dataloader,loss_fn,optimizer,device):\n",
    "    for input, output in dataloader:\n",
    "        #forward pass \n",
    "        input = input.to(device)\n",
    "        output = output.to(device)\n",
    "        outputs = model(input)\n",
    "        loss = loss_fn(outputs, output)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"loss:{loss.item()}\")\n",
    "    \n",
    "\n",
    "def train(model,dataloader,loss_fn,optimizer,device,num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        one_epoch(model,dataloader,loss_fn=criterion,optimizer=optimizer,device=device)\n",
    "\n",
    "\n",
    "train(net,noisy_trainDataloader,criterion,optimizer,device,num_epoch)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GUI\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "waveform = None\n",
    "sample_rate = None\n",
    "\n",
    "def open_file():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    global waveform\n",
    "    global sample_rate\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    return waveform, sample_rate\n",
    "\n",
    "def download_file():\n",
    "    file_path = filedialog.asksaveasfilename()\n",
    "    if waveform is None or sample_rate is None:\n",
    "        print(\"No file to save\")\n",
    "        return\n",
    "    torchaudio.save(file_path, waveform, sample_rate)\n",
    "    return\n",
    "    \n",
    "def run_model():\n",
    "    #run the model\n",
    "    pass\n",
    "\n",
    "#3 buttons, one to ask for audio file and one to run the model, and another to download the file\n",
    "root = tk.Tk()\n",
    "root.title(\"Audio Denoising\")\n",
    "root.geometry(\"400x400\")\n",
    "button1 = tk.Button(root, text=\"Open File\", command=open_file)\n",
    "button1.pack()\n",
    "button2 = tk.Button(root, text=\"Run Model\", command=run_model)\n",
    "button2.pack()\n",
    "button3 = tk.Button(root, text=\"Download File\", command=download_file)\n",
    "button3.pack()\n",
    "root.mainloop()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
